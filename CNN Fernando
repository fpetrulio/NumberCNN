Al fine di elaborare le immagini dei numeri scritti a mano, abbiamo deciso di sviluppare una rete neurale convulazionale (CNN o ConvNet). Questa è un tipo di rete neurale artificiale feed-forward in cui il pattern di connettività tra i suoi neuroni è ispirato dall'organizzazione della corteccia visiva animale, i cui neuroni individuali sono disposti in maniera tale da rispondere alle regioni di sovrapposizione che tassellano il campo visivo. Le reti convoluzionali sono ispirate da processi biologici e sono variazioni di percettroni multistrato progettate per usare al minimo la pre-elaborazione. Hanno diverse applicazioni nel riconoscimento di immagini e video, nei sistemi di raccomandazione, nell'elaborazione del linguaggio naturale e, recentemente, in bioinformatica. In genere le CNN sono composte da più strati convulazionali alternati a strati di pooling per ridurre gradualmente la complessità di calcolo, per poi infine convogliare in strati pienamente connessi atti alla classificazione vera e propria. Per realizzare questa rete abbiamo scelto come linguaggio di programmazione Python il quale supporta innumerevoli librerie e framework dedicate al deep learning, tra cui Tensorflow. Al fine di interfacciarci con quest'ultimo abbiamo utilizzato le API di Keras per l'implementazione del modello della rete neurale e le librerie di scikit-learn per importare le metriche di testing e per la creazione della Confusion Matrix.
La nostra CNN è comporta da due layer convulazionali con funzione di attivazione ReLU, ciascuno seguito da un layer di Pooling, per poi infine produrre un array mono-dimensionale con un Flatten Layer associato a due layer finali di tipo Fully Connected. Andremo quindi ad ispezionare più da vicino il significato di ogni layer.

Layer Convulazionale
Un Layer Convulazionale estrae le Feature da una immagine. La convoluzione preserva la relazione tra i pixel attraverso l'apprendimento delle feature utilizzando piccole matrici di dati in input. Nello specifico, esegue una operazione matematica applicando uno o più filtri di tipo maschera all'immagine stessa. Nel codice prodotto, entrambi in nostri layer di convoluzione applicano 32 filtri 3x3  traslati lungo altezza e lunghezza dell'immagine di input (quindi non in profondità). Applicare questi filtri con un layer convulazionale equivale a produrre una mappa delle feature, detta Activation Map, la quale estrae i pixel trasformati corrispondenti a delle peculiarità dell'immagine rese evidenti dal filtraggio. Questa mappa siffatta viene quindi a propria volta filtrata tramite una funzione di attivazione (Activation Function). Lo scopo è quella di normalizzare o di preservare soltanto il valore di taluni pixel prodotti dopo la convulazione. Nel nostro progetto  abbiamo utilizzato una funzione di attivazione di tipo ReLU (Rectificie Linear Unit), la quale effettua un filtro di tipo soglia eliminando tutti i valori negativi, riducendoli a 0. La scelta di questo tipo di funzione di attivazione è stata dettata dalle performace della stessa nelle reti convulazionali atte alla classificazione categorica piuttosto che binaria.

Pooling Layer
I layer convulazionali sono interposti con dei layer di Pooling. Lo scopo di questi è quello di ridurre la dimensione spaziale (eccetto per la profondità) della rete neruale al fine di incrementare le performance della stessa. Oltre all'evidente vantaggio computazionale, si riducono le chance di over-fitting in quanto anche la quantità di parametri viene ridotta. I nostri layer di Max Pooling applicano dei filtri 2x2 lungo le suddette dimensioni i quali preservano solo i valori massimi nelle porzioni esaminate. Quindi, benchè le N immagini di test constituivano un tensore iniziale di dimensione Nx128x128x3, con i 2 processi di pooling si ottengono rispettivamente un tensore N x 64 x 64 x 3, dato in pasto al secondo layer convulazionale, ed uno N x 32 x 32 x 3, ovvero l'input per il Flatten Layer. 

Flatten Layer
Il flatten layer ha l'unico scopo trasformare il tensore tridimensionale in input (la cui dimensione ricordiamo e Nx32x32x3) in un tensore monodimensionale nel quale ogni elemento è rappresentativo delle feature individuate in ciascuna delle immagini presenti nel tensore di iniziale. Questo layer è necessario nel momento in cui bisogna introdurre dei layer fully connected. Poichè in ingresso riceve N x (32x32x3) immagini fitrate, verranno quindi prodotto un output di dimensione N x 3072.

Fully Connected Layer
Infine la nostra rete si compone di due Layer pienamente connessi. Il primo è composto da 128 neuroni, ognuno dei quali connesso pienamente con i neuroni del layer precedente, ed è a sua volta pienamente connesso con il secondo, comprensivo di 10 neuroni ognuno atto a classificare una delle 10 cifre numeriche che si vuole riconoscere. Mentre al primo layer Fully Connected viene applicata la funzione di attivazione ReLU, al secondo viene applicata una funzione di tipo Softmax la quale riconduce il valore assunto dai neuroni ad un numero nel range (0,1) che rispecchia la probabilità che l'immagine in esame appartenga alla classe rappresentata dal neurone stesso. Il Neurone con il valore più alto rappresenta la classe di predizione per l'input in esame.
